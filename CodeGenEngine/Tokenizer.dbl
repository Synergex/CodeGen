;; *****************************************************************************
;; 
;;  Title:       Tokenizer.dbl
;; 
;;  Type:        Class
;; 
;;  Description: Transforms raw template data into a list of tokens
;; 
;;  Date:        30th August 2014
;; 
;;  Author:      Jeff Greene, Synergex Development
;;               http://www.synergex.com
;; 
;; *****************************************************************************
;; 
;;  Copyright (c) 2014, Synergex International, Inc.
;;  All rights reserved.
;; 
;;  Redistribution and use in source and binary forms, with or without
;;  modification, are permitted provided that the following conditions are met:
;; 
;;  * Redistributions of source code must retain the above copyright notice,
;;    this list of conditions and the following disclaimer.
;; 
;;  * Redistributions in binary form must reproduce the above copyright notice,
;;    this list of conditions and the following disclaimer in the documentation
;;    and/or other materials provided with the distribution.
;; 
;;  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
;;  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
;;  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
;;  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
;;  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
;;  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
;;  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
;;  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
;;  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
;;  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
;;  POSSIBILITY OF SUCH DAMAGE.
;; 
;; *****************************************************************************

import System
import System.Collections.Generic
import System.IO
import System.Linq

.array 0

namespace CodeGen.Engine
	
	;;; <summary>
	;;; Transforms raw template data into a list of tokens.
	;;; </summary>
	public class Tokenizer
		
		;; typeLookup contains an entry for every supported non-expression token (expansion, loops, control, file header, etc.)
		;; and defines the type of token (TokenType).
		private typeLookup, @Dictionary<string, TokenType>, new Dictionary<string, TokenType>()

		;; requiresRps contains an entry for each token that relies on a repository structure being processed
		private requiresRps, @Dictionary<string, boolean>, new Dictionary<string, boolean>()

		;; requiresNamespace contains an entry for each token that relies on a namespace being specified
		private requiresNamespace, @Dictionary<string, boolean>, new Dictionary<string, boolean>()

		;; validityLookup contains an entry for every supported non-expression token (expansion, loops, control, file header, etc.) and defines where in a template each is valid.
		private validityLookup, @Dictionary<string, List<TokenValidity>>, new Dictionary<string, List<TokenValidity>>()

		;; modifierLookup contains an entry for every supported expansion token variation
		private modifierLookup, @Dictionary<string, TokenModifier>, new Dictionary<string, TokenModifier>()

		;; expressionLookup has an entry for every supported expression token, and defines where in a template each is valid
		private expressionLookup, @Dictionary<String, List<TokenValidity>>, new Dictionary<string, List<TokenValidity>>()

		;; closerLookup is a collection of valid closer token names. It is used to determine if a token name beginning with / is valid
		private closerLookup, @HashSet<string>, new HashSet<string>()

		;; canonicalNameLookup seems lind of pointless. It seems to contain matching names for opener and closer tokens, but the kay and value are always the same? I assume it isn't being used anywhere?
		private canonicalNameLookup, @Dictionary<string, string>, new Dictionary<string, string>()

		private customValidity, @List<TokenValidity>
		private userTokenValidity, @List<TokenValidity>
		private loopUtilityTokenValidity, @List<TokenValidity>

		private context, @CodeGenContext
		private errorsReported, boolean, false
		
		;; This is a collection of the expansion values for "pre-processor" type optional user tokens. These are optional user tokens who's value includes other tokens.
		private optionalUserTokens, @Dictionary<string, List<Token>>, new Dictionary<string, List<Token>>()
		
		;;; <summary>
		;;; This constructor should be used if you're trying to do "real" tokenization. 
		;;; Context is passed in so that the tokenizer is aware of user-defined tokens and custom extensions.
		;;; </summary>
		;;; <param name="aContext">Code generator context.</param>
		public method Tokenizer
			default in aContext, @CodeGenContext, ^null
		proc
			;; For use later (error reporting during Tokenize)
			context = aContext

			customValidity = new List<TokenValidity>()
			customValidity.Add(TokenValidity.FieldLoop)

			userTokenValidity = new List<TokenValidity>()
			userTokenValidity.Add(TokenValidity.Anywhere)

			loopUtilityTokenValidity = new List<TokenValidity>()
			loopUtilityTokenValidity.Add(TokenValidity.AnyLoop)

			;; Declare all the special and expansion tokens

			data metaLookup, @List<TokenMeta>, new List<TokenMeta>() {
			&	
			&	{ new TokenMeta() {Name = "CODEGEN_FILENAME", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "CODEGEN_FOLDER", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "OPTIONAL_USERTOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "PROCESS_TEMPLATE", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "PROVIDE_FILE", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CODEGEN_VERSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_OPTION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_USERTOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_BUTTON_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_BUTTON_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_ENUM_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_ENUM_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_ENUM_MEMBER_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_ENUM_MEMBER_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_FIELD_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_FIELD_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_FILE_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_FILE_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_KEY_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_KEY_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_LOOPUTIL_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_LOOPUTIL_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_NOTINLOOP_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_NOTINLOOP_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_RELATION_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_RELATION_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_SEGMENT_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_SEGMENT_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_SELECTION_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_SELECTION_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_STRUCTLOOP_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_STRUCTLOOP_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_TAG_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_TAG_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_EXPRESSION", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "REQUIRES_CUSTOM_TOKEN", TypeOfToken = TokenType.FileHeader, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	
			&	{ new TokenMeta() {Name = "ENV", TypeOfToken = TokenType.PreProcessor, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "ENVIFEXIST", TypeOfToken = TokenType.PreProcessor, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "FILE", TypeOfToken = TokenType.PreProcessor, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "FILEIFEXIST", TypeOfToken = TokenType.PreProcessor, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	
			&	{ new TokenMeta() {Name = "STRUCTURE_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "FIELD_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "ALTERNATE_KEY_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "PRIMARY_KEY", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "UNIQUE_KEY", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} },
			&	{ new TokenMeta() {Name = "ENUM_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "ENUM_LOOP_STRUCTURE", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "RELATION_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FILE_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "TAG_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop | TokenValidity.StructureLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "BUTTON_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.NotInLoop} }, 
			&	
			&	{ new TokenMeta() {Name = "SELECTION_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.FieldLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SEGMENT_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SEGMENT_LOOP_FILTER", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIRST_SEGMENT", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SECOND_SEGMENT", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "ENUM_MEMBER_LOOP", TypeOfToken = TokenType.Loop, IsPaired = true, Validity = TokenValidity.EnumLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "AUTHOR", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "CODEGEN_VERSION", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "COMPANY", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "DATABASE", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "DATE", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "DATE1", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "DAY", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "FIELD_PREFIX", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "GUID1", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "GUID2", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "GUID3", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ makeTokenMeta_UpperLower ("HOST_DNS_NAME", TokenType.Generic, TokenValidity.Anywhere, false) }, 
			&	{ new TokenMeta() {Name = "HOST_IP_ADDRESS", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ makeTokenMeta_UpperLower ("MACHINE_NAME", TokenType.Generic, TokenValidity.Anywhere, false) }, 
			&	{ new TokenMeta() {Name = "MONTH", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "MONTHNAME", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "MONTHSHORTNAME", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "NAMESPACE", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresNamespace = true} }, 
			&	{ new TokenMeta() {Name = "OS_IDENTIFIER", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "OS_PLATFORM", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "OS_SERVICE_PACK", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "OS_VERSION", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "RANDOM_10", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "RANDOM_100", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "RANDOM_1000", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "RANDOM_INT", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ makeTokenMeta_UpperLower ("TEMPLATE", TokenType.Generic, TokenValidity.Anywhere, false) }, 
			&	{ new TokenMeta() {Name = "TIME", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "WEEKDAY", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "YEAR", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	
			&	{ new TokenMeta() {Name = "GOAT", TypeOfToken = TokenType.Generic, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	
			&	{ new TokenMeta() {Name = "DATA_FIELDS_LIST", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "DISPLAY_FIELD", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FILE_ADDRESSING", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("FILE_CHANGE_TRACKING", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ makeTokenMeta_UpperLower ("FILE_COMPRESSION", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ new TokenMeta() {Name = "FILE_DENSITY", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FILE_DESC", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FILE_NAME", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FILE_NAME_NOEXT", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FILE_ODBC_NAME", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ new TokenMeta() {Name = "FILE_PAGESIZE", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("FILE_RECTYPE", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ makeTokenMeta_AllVariants("FILE_RPS_NAME", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ makeTokenMeta_UpperLower ("FILE_STATIC_RFA", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ makeTokenMeta_UpperLower ("FILE_STORED_GRFA", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ new TokenMeta() {Name = "FILE_TYPE", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FILE_UTEXT", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("MAPPED_FILE", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ makeTokenMeta_UpperLower ("MAPPED_STRUCTURE", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ makeTokenMeta_AllVariants("PRIMARY_KEY_FIELD", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	
			&	{ new TokenMeta() {Name = "STRUCTURE_CHILDREN", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE_DESC", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE_FIELDS", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE_KEYS", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE_LDESC", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("STRUCTURE_NAME", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ makeTokenMeta_AllVariants("STRUCTURE_NOALIAS", TokenType.StructureInfo, TokenValidity.Anywhere, true) }, 
			&	{ new TokenMeta() {Name = "STRUCTURE_SIZE", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE_UTEXT", TypeOfToken = TokenType.StructureInfo, IsPaired = false, Validity = TokenValidity.Anywhere, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = ",", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "+", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = ":", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "&&", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = ".AND.", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "AND", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "||", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = ".OR.", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "OR", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "BSLASH", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "FSLASH", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "PROCESSED_INCLUSIVE", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "PROCESSED_EXCLUSIVE", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "REMAINING_INCLUSIVE", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "REMAINING_EXCLUSIVE", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	{ new TokenMeta() {Name = "TOTAL_ITEMS", TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop} }, 
			&	
			&	{ new TokenMeta() {Name = "FIELD#", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD#_ZERO", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD#LOGICAL", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD#LOGICAL_ZERO", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_ALTNAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FIELD_ARRIVEM", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FIELD_BASENAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_BREAK_MODE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_CHANGEM", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_COL", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_CSCONVERT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_CSDEFAULT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_CSTYPE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_DEFAULT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_DESC", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_DIMENSION1_INDEX", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_DIMENSION2_INDEX", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_DIMENSION3_INDEX", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_DIMENSION4_INDEX", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_DRILLM", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_DRILL_PIXEL_COL", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_ELEMENT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_ELEMENT0", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_ENUMLENGTH", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_ENUMWIDTH", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_FORMATNAME", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_FORMATSTRING", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_HEADING", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_HELPID", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_HYPERM", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_INFOLINE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_INPUT_LENGTH", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_LDESC", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_LEAVEM", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_MAXVALUE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_MINVALUE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_NAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FIELD_NETNAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_NOECHO_CHAR", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_OCDEFAULT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_OCTYPE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_ODBCNAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FIELD_ORIGINAL_NAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FIELD_PATH", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_UpperLower ("FIELD_PATH_CONV", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_PIXEL_COL", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_PIXEL_ROW", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_PIXEL_WIDTH", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_POSITION", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_POSITION_ZERO", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_PRECISION", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_PRECISION0", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_PRECISION2", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_PROMPT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_RANGE_MAX", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_RANGE_MIN", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_REGEX", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_ROW", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_SELECTION_COUNT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_SELECTIONS", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_SELECTIONS1", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_SELLENGTH", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_SELWND", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_SELWND_ORIGINAL", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_SIZE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_SNDEFAULT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_SNTYPE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_SPEC", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FIELD_SQLNAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FIELD_NET_ALTNAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FIELD_SQL_ALTNAME", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_SQLTYPE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_TEMPLATE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_TKSCRIPT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FIELD_TYPE", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "FIELD_TYPE_NAME", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_UTEXT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_VBDEFAULT", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FIELD_VBTYPE", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("MAPPED_FIELD", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_UpperLower ("MAPPED_PATH", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_UpperLower ("MAPPED_PATH_CONV", TokenType.FieldLoop, TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "PROMPT_COL", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "PROMPT_PIXEL_COL", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "PROMPT_PIXEL_ROW", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "PROMPT_PIXEL_WIDTH", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "PROMPT_ROW", TypeOfToken = TokenType.FieldLoop, IsPaired = false, Validity = TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "SELECTION_COUNT", TypeOfToken = TokenType.FieldSelectionLoop, IsPaired = false, Validity = TokenValidity.FieldSelectionLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SELECTION_NUMBER", TypeOfToken = TokenType.FieldSelectionLoop, IsPaired = false, Validity = TokenValidity.FieldSelectionLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SELECTION_TEXT", TypeOfToken = TokenType.FieldSelectionLoop, IsPaired = false, Validity = TokenValidity.FieldSelectionLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SELECTION_VALUE", TypeOfToken = TokenType.FieldSelectionLoop, IsPaired = false, Validity = TokenValidity.FieldSelectionLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "KEY_CHANGES", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_DENSITY", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_DESCRIPTION", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_DUPLICATES", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_DUPLICATES_AT", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_LENGTH", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("KEY_NAME", TokenType.KeyLoop, TokenValidity.KeyLoop, true) }, 
			&	{ makeTokenMeta_UpperLower ("KEY_NULLTYPE", TokenType.KeyLoop, TokenValidity.KeyLoop, true) }, 
			&	{ new TokenMeta() {Name = "KEY_NULLVALUE", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_NUMBER", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_ORDER", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_SEGMENTS", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "KEY_UNIQUE", TypeOfToken = TokenType.KeyLoop, IsPaired = false, Validity = TokenValidity.KeyLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "SEGMENT_CSTYPE", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SEGMENT_DESC", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SEGMENT_IDXTYPE", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SEGMENT_KIND", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SEGMENT_LENGTH", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "SEGMENT_LITVAL", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("SEGMENT_MAPPEDNAME", TokenType.KeySegmentLoop, TokenValidity.KeySegmentLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("SEGMENT_NAME", TokenType.KeySegmentLoop, TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "SEGMENT_NUMBER", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("SEGMENT_ORDER", TokenType.KeySegmentLoop, TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "SEGMENT_POSITION", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("SEGMENT_SEQUENCE", TokenType.KeySegmentLoop, TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "SEGMENT_SNTYPE", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("SEGMENT_SPEC", TokenType.KeySegmentLoop, TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "SEGMENT_STRUCTURE", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("SEGMENT_TYPE", TokenType.KeySegmentLoop, TokenValidity.KeySegmentLoop, true) }, 
			&	{ new TokenMeta() {Name = "SEGMENT_VBTYPE", TypeOfToken = TokenType.KeySegmentLoop, IsPaired = false, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "ENUM_COUNT", TypeOfToken = TokenType.EnumLoop, IsPaired = false, Validity = TokenValidity.EnumLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "ENUM_DESCRIPTION", TypeOfToken = TokenType.EnumLoop, IsPaired = false, Validity = TokenValidity.EnumLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "ENUM_LONG_DESCRIPTION", TypeOfToken = TokenType.EnumLoop, IsPaired = false, Validity = TokenValidity.EnumLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "ENUM_MEMBER_COUNT", TypeOfToken = TokenType.EnumLoop, IsPaired = false, Validity = TokenValidity.EnumLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("ENUM_NAME", TokenType.EnumLoop, TokenValidity.EnumLoop, true) }, 
			&	{ new TokenMeta() {Name = "ENUM_NUMBER", TypeOfToken = TokenType.EnumLoop, IsPaired = false, Validity = TokenValidity.EnumLoop, RequiresRepository = true} }, 
			&	
			&	{ makeTokenMeta_AllVariants("ENUM_MEMBER_NAME", TokenType.EnumMemberLoop, TokenValidity.EnumMemberLoop, true) }, 
			&	{ new TokenMeta() {Name = "ENUM_MEMBER_EXPLICIT_VALUE", TypeOfToken = TokenType.EnumMemberLoop, IsPaired = false, Validity = TokenValidity.EnumMemberLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "ENUM_MEMBER_IMPLICIT_VALUE", TypeOfToken = TokenType.EnumMemberLoop, IsPaired = false, Validity = TokenValidity.EnumMemberLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "RELATION_NUMBER", TypeOfToken = TokenType.RelationLoop, IsPaired = false, Validity = TokenValidity.RelationLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "RELATION_NAME", TypeOfToken = TokenType.RelationLoop, IsPaired = false, Validity = TokenValidity.RelationLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "RELATION_FROMKEY", TypeOfToken = TokenType.RelationLoop, IsPaired = false, Validity = TokenValidity.RelationLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "RELATION_TOKEY", TypeOfToken = TokenType.RelationLoop, IsPaired = false, Validity = TokenValidity.RelationLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "RELATION_TOSTRUCTURE", TypeOfToken = TokenType.RelationLoop, IsPaired = false, Validity = TokenValidity.RelationLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "BUTTON_CAPTION", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_COLPX", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_ELB", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_IMAGE", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_METHOD", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_NAME", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_NUMBER", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_QUICKSELECT", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_ROWPX", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	{ new TokenMeta() {Name = "BUTTON_WIDTHPX", TypeOfToken = TokenType.ButtonLoop, IsPaired = false, Validity = TokenValidity.ButtonLoop} }, 
			&	
			&	{ new TokenMeta() {Name = "FLOOP_ADDRESSING", TypeOfToken = TokenType.FileLoop, IsPaired = false, Validity = TokenValidity.FileLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("FLOOP_COMPRESSION", TokenType.FileLoop, TokenValidity.FileLoop, true) }, 
			&	{ makeTokenMeta_UpperLower ("FLOOP_CHANGE_TRACKING", TokenType.FileLoop, TokenValidity.FileLoop, true) }, 
			&	{ new TokenMeta() {Name = "FLOOP_DESC", TypeOfToken = TokenType.FileLoop, IsPaired = false, Validity = TokenValidity.FileLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FLOOP_DENSITY", TypeOfToken = TokenType.FileLoop, IsPaired = false, Validity = TokenValidity.FileLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FLOOP_NAME", TypeOfToken = TokenType.FileLoop, IsPaired = false, Validity = TokenValidity.FileLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FLOOP_NAME_NOEXT", TypeOfToken = TokenType.FileLoop, IsPaired = false, Validity = TokenValidity.FileLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_AllVariants("FLOOP_ODBC_NAME", TokenType.FileLoop, TokenValidity.FileLoop, true) }, 
			&	{ new TokenMeta() {Name = "FLOOP_PAGESIZE", TypeOfToken = TokenType.FileLoop, IsPaired = false, Validity = TokenValidity.FileLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("FLOOP_RECTYPE", TokenType.FileLoop, TokenValidity.FileLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("FLOOP_RPS_NAME", TokenType.FileLoop, TokenValidity.FileLoop, true) }, 
			&	{ makeTokenMeta_UpperLower ("FLOOP_STATIC_RFA", TokenType.FileLoop, TokenValidity.FileLoop, true) }, 
			&	{ makeTokenMeta_UpperLower ("FLOOP_STORED_GRFA", TokenType.FileLoop, TokenValidity.FileLoop, true) }, 
			&	{ new TokenMeta() {Name = "FLOOP_TYPE", TypeOfToken = TokenType.FileLoop, IsPaired = false, Validity = TokenValidity.FileLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "FLOOP_UTEXT", TypeOfToken = TokenType.FileLoop, IsPaired = false, Validity = TokenValidity.FileLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "TAGLOOP_CONNECTOR_C", TypeOfToken = TokenType.TagLoop, IsPaired = false, Validity = TokenValidity.TagLoop, RequiresRepository = true} }, 
			&	{ makeTokenMeta_UpperLower ("TAGLOOP_CONNECTOR_DBL", TokenType.TagLoop, TokenValidity.TagLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("TAGLOOP_FIELD_ALTNAME", TokenType.TagLoop, TokenValidity.TagLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("TAGLOOP_FIELD_BASENAME", TokenType.TagLoop, TokenValidity.TagLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("TAGLOOP_FIELD_NAME", TokenType.TagLoop, TokenValidity.TagLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("TAGLOOP_FIELD_ODBCNAME", TokenType.TagLoop, TokenValidity.TagLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("TAGLOOP_FIELD_ORIGINALNAME", TokenType.TagLoop, TokenValidity.TagLoop, true) }, 
			&	{ makeTokenMeta_AllVariants("TAGLOOP_FIELD_SQLNAME", TokenType.TagLoop, TokenValidity.TagLoop, true) }, 
			&	{ makeTokenMeta_UpperLower ("TAGLOOP_OPERATOR_DBL", TokenType.TagLoop, TokenValidity.TagLoop, true) }, 
			&	{ new TokenMeta() {Name = "TAGLOOP_OPERATOR_C", TypeOfToken = TokenType.TagLoop, IsPaired = false, Validity = TokenValidity.TagLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "TAGLOOP_SEQUENCE", TypeOfToken = TokenType.TagLoop, IsPaired = false, Validity = TokenValidity.TagLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "TAGLOOP_TAG_NAME", TypeOfToken = TokenType.TagLoop, IsPaired = false, Validity = TokenValidity.TagLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "TAGLOOP_TAG_VALUE", TypeOfToken = TokenType.TagLoop, IsPaired = false, Validity = TokenValidity.TagLoop, RequiresRepository = true} }, 
			&	
			&	{ new TokenMeta() {Name = "WINDOW_HEIGHT", TypeOfToken = TokenType.Window, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "WINDOW_HEIGHTPX", TypeOfToken = TokenType.Window, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ makeTokenMeta_AllVariants("WINDOW_NAME", TokenType.Window, TokenValidity.Anywhere, false) }, 
			&	{ new TokenMeta() {Name = "WINDOW_WIDTH", TypeOfToken = TokenType.Window, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "WINDOW_WIDTHPX", TypeOfToken = TokenType.Window, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	
			&	{ new TokenMeta() {Name = "COUNTER_1_INCREMENT", TypeOfToken = TokenType.CounterInstruction, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "COUNTER_1_DECREMENT", TypeOfToken = TokenType.CounterInstruction, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "COUNTER_1_RESET", TypeOfToken = TokenType.CounterInstruction, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "COUNTER_1_VALUE", TypeOfToken = TokenType.Counter, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "COUNTER_2_INCREMENT", TypeOfToken = TokenType.CounterInstruction, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "COUNTER_2_DECREMENT", TypeOfToken = TokenType.CounterInstruction, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "COUNTER_2_RESET", TypeOfToken = TokenType.CounterInstruction, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "COUNTER_2_VALUE", TypeOfToken = TokenType.Counter, IsPaired = false, Validity = TokenValidity.Anywhere} }, 
			&	
			&	{ new TokenMeta() {Name = "IF", TypeOfToken = TokenType.Control, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	{ new TokenMeta() {Name = "ELSE", TypeOfToken = TokenType.Control, IsPaired = true, Validity = TokenValidity.Anywhere} }, 
			&	
			&	{ new TokenMeta() {Name = "STRUCTURE#1", TypeOfToken = TokenType.NotInLoop, IsPaired = false, Validity = TokenValidity.NotInLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE#2", TypeOfToken = TokenType.NotInLoop, IsPaired = false, Validity = TokenValidity.NotInLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE#3", TypeOfToken = TokenType.NotInLoop, IsPaired = false, Validity = TokenValidity.NotInLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE#4", TypeOfToken = TokenType.NotInLoop, IsPaired = false, Validity = TokenValidity.NotInLoop, RequiresRepository = true} }, 
			&	{ new TokenMeta() {Name = "STRUCTURE#5", TypeOfToken = TokenType.NotInLoop, IsPaired = false, Validity = TokenValidity.NotInLoop, RequiresRepository = true} }}


			;; Apply non-standard customizations. These are here for historic reasons because of errors made when implementing token names in earlier versions.

			data tm, @TokenMeta
			foreach tm in metaLookup
			begin
				using (tm.Name) select
				("FIELD_NETNAME"),
				begin
					tm.Modifiers.Add("FieldNetName", TokenModifier.PascalCase)
					tm.Modifiers.Add("fieldNetName", TokenModifier.CamelCase)
				end
				("FIELD_ODBCNAME"),
				begin
					tm.Modifiers.Add("FieldOdbcName", TokenModifier.PascalCase)
					tm.Modifiers.Add("fieldOdbcName", TokenModifier.CamelCase)
				end
				("FIELD_SQLNAME"),
				begin
					tm.Modifiers.Add("FieldSqlName", TokenModifier.PascalCase)
					tm.Modifiers.Add("fieldSqlName", TokenModifier.CamelCase)
				end
				endusing
			end

			;; Process each of the replacement tokens, adding them to the various lookup collections
			foreach tm in metaLookup
				addLookupToken(tm)

			;; This lambda processes the Dictionary of expression tokens declared below into the expresionLookup collection.
			;; It is required because the declaration of expressions can a include bitwise OR of multiple valid TokenValidity
			;; settings. The lambda parses those out into a List<TokenVisibility> for ease of use elsewhere.
			lambda doLoadExpressionLookup(initial)
			begin
				data result = new Dictionary<string, List<TokenValidity>>()
				data exprTpl, KeyValuePair<string, TokenValidity>
				foreach exprTpl in initial
				begin
					data expressionTypes = new List<TokenValidity>()
					data enumValue, Enum
					foreach enumValue in Enum.GetValues(exprTpl.Value.GetType())
						if (exprTpl.Value.HasFlag(enumValue))
							expressionTypes.Add((TokenValidity)enumValue)
					result.Add(exprTpl.Key, expressionTypes)
				end
				
				mreturn result
			end

			data loadExpressionLookup, @Func<Dictionary<string, TokenValidity>, Dictionary<string, List<TokenValidity>>>, doLoadExpressionLookup

			;; Declare all of the expression tokens that we support. Multiple TokenValidity options can
			;; be specified by bitwise ORing the values together. See the notes on the expressionLookupHelper
			;; lambda above.

			data expressions = new Dictionary<string, TokenValidity>()

			expressions.Add("ALLOW_LIST", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ALPHA", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ALTERNATE_NAME", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ARRAY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ARRAY_FIRST", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ARRAY1", TokenValidity.FieldLoop)
			expressions.Add("ARRAY1_FIRST", TokenValidity.FieldLoop)
			expressions.Add("ARRAY2", TokenValidity.FieldLoop)
			expressions.Add("ARRAY2_FIRST", TokenValidity.FieldLoop)
			expressions.Add("ARRAY3", TokenValidity.FieldLoop)
			expressions.Add("ARRAY3_FIRST", TokenValidity.FieldLoop)
			expressions.Add("ARRAY4", TokenValidity.FieldLoop)
			expressions.Add("ARRAY4_FIRST", TokenValidity.FieldLoop)
			expressions.Add("ARRIVE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ASCENDING", TokenValidity.KeyLoop)
			expressions.Add("ASCII", TokenValidity.FileLoop)
			expressions.Add("AUTO_SEQUENCE", TokenValidity.FieldLoop | TokenValidity.KeyLoop)
			expressions.Add("AUTO_TIMESTAMP", TokenValidity.FieldLoop | TokenValidity.KeyLoop)
			expressions.Add("AUTO_TIMESTAMP_CREATED", TokenValidity.FieldLoop | TokenValidity.KeyLoop)
			expressions.Add("AUTO_TIMESTAMP_UPDATED", TokenValidity.FieldLoop | TokenValidity.KeyLoop)
			expressions.Add("BINARY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("BOLD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("BOOLEAN", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("BREAK", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("BREAK_ALWAYS", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("BREAK_CHANGE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("BREAK_RETURN", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("BZERO", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("CANCEL_BUTTON", TokenValidity.ButtonLoop)
			expressions.Add("CANCELBUTTON", TokenValidity.ButtonLoop)
			expressions.Add("CAPTION", TokenValidity.ButtonLoop)
			expressions.Add("CHANGE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("CHANGE_TRACKING", TokenValidity.FileLoop)
			expressions.Add("CHANGES", TokenValidity.KeyLoop)
			expressions.Add("CHECKBOX", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("COERCEBOOLEAN", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("COMBOBOX", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("COMPARISON_EQ", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_GE", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_GT", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_LE", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_LT", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_NE", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_NOT_EQ", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_NOT_GE", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_NOT_GT", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_NOT_LE", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_NOT_LT", TokenValidity.TagLoop)
			expressions.Add("COMPARISON_NOT_NE", TokenValidity.TagLoop)
			expressions.Add("CONNECTOR_AND", TokenValidity.TagLoop)
			expressions.Add("CONNECTOR_NONE", TokenValidity.TagLoop)
			expressions.Add("CONNECTOR_NOT_AND", TokenValidity.TagLoop)
			expressions.Add("CONNECTOR_NOT_NONE", TokenValidity.TagLoop)
			expressions.Add("CONNECTOR_NOT_OR", TokenValidity.TagLoop)
			expressions.Add("CONNECTOR_OR", TokenValidity.TagLoop)
			expressions.Add("COUNTER_1", TokenValidity.Anywhere)
			expressions.Add("COUNTER_2", TokenValidity.Anywhere)
			expressions.Add("CUSTOM_", TokenValidity.FieldLoop)
			expressions.Add("CUSTOM_NOT_", TokenValidity.FieldLoop)
			expressions.Add("DATABASE_MYSQL", TokenValidity.Anywhere)
			expressions.Add("DATABASE_POSTGRESQL", TokenValidity.Anywhere)
			expressions.Add("DATABASE_SQLSERVER", TokenValidity.Anywhere)
			expressions.Add("DATE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_JULIAN", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_NOT_JULIAN", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_NOT_NULLABLE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_NOT_PERIOD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_NOT_YMD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_NOT_YYYYMMDD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_NULLABLE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_PERIOD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_YMD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_YYJJJ", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_YYMMDD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_YYPP", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_YYYYJJJ", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_YYYYMMDD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATE_YYYYPP", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATEORTIME", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DATETODAY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DEBUG_LOGGING", TokenValidity.Anywhere)
			expressions.Add("DECIMAL", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DEFAULT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DESCENDING", TokenValidity.KeyLoop)
			expressions.Add("DESCRIPTION", TokenValidity.FieldLoop | TokenValidity.EnumLoop | TokenValidity.FileLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DISABLED", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DISPLAY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DISPLAY_LENGTH", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DRILL", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("DUPLICATES", TokenValidity.KeyLoop)
			expressions.Add("DUPLICATESATFRONT", TokenValidity.KeyLoop)
			expressions.Add("DUPLICATESATEND", TokenValidity.KeyLoop)
			expressions.Add("ECHO", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("EDITFORMAT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ELB", TokenValidity.ButtonLoop)
			expressions.Add("ENABLED", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ENUM", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ENUMERATED", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("EXPLICIT_VALUE", TokenValidity.EnumMemberLoop)
			expressions.Add("FIELD_POSITION", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("FIELD_PREFIX", TokenValidity.Anywhere)
			expressions.Add("FIELD_SUBSET", TokenValidity.Anywhere)
			expressions.Add("FIRST", TokenValidity.FieldLoop | TokenValidity.FieldSelectionLoop | TokenValidity.ButtonLoop | TokenValidity.EnumLoop | TokenValidity.EnumMemberLoop | TokenValidity.FileLoop | TokenValidity.KeyLoop | TokenValidity.TagLoop)
			expressions.Add("FIRST_SEG_NOCASE", TokenValidity.KeyLoop)
			expressions.Add("FORMAT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("GENERICBUTTON", TokenValidity.ButtonLoop)
			expressions.Add("GROUP_EXPAND", TokenValidity.FieldLoop)
			expressions.Add("GROUP_NO_EXPAND", TokenValidity.FieldLoop)
			expressions.Add("HEADING", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("HELPID", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("HYPERLINK", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("I1", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("I124", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("I2", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("I4", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("I8", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("IMAGE", TokenValidity.ButtonLoop)
			expressions.Add("INCREMENT", TokenValidity.KeySegmentLoop)
			expressions.Add("INFOLINE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop | TokenValidity.FieldSelectionLoop)
			expressions.Add("INPUT_CENTER", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("INPUT_LEFT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("INPUT_RIGHT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("INTEGER", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("ISAM", TokenValidity.FileLoop)
			expressions.Add("LANGUAGE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("LAST", TokenValidity.FieldLoop | TokenValidity.FieldSelectionLoop | TokenValidity.TagLoop)
			expressions.Add("LEAVE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("LENGTH_OVER_8", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("LONG_DESCRIPTION", TokenValidity.EnumLoop)
			expressions.Add("LONGDESC", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("MAPPED", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("MAPPEDSTR", TokenValidity.FieldLoop)
			expressions.Add("METHOD", TokenValidity.ButtonLoop)
			expressions.Add("MORE", TokenValidity.AnyLoop)
			expressions.Add("MULTIPLE_SEGMENTS", TokenValidity.KeyLoop)
			expressions.Add("MULTIPLE_STRUCTURES", TokenValidity.Anywhere)
			expressions.Add("MULTIPLE_TAGS", TokenValidity.TagLoop)
			expressions.Add("NAMESPACE", TokenValidity.Anywhere)
			expressions.Add("NEGATIVE_ALLOWED", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NEGATIVE_ORZERO", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NEGATIVE_REQUIRED", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOALLOW_LIST", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOALTERNATE_NAME", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOARRIVE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOBREAK", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOCHANGE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOCHANGE_TRACKING", TokenValidity.FileLoop)
			expressions.Add("NOCHANGES", TokenValidity.KeyLoop)
			expressions.Add("NOCHECKBOX", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOCOERCEBOOLEAN", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NODEFAULT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NODESCRIPTION", TokenValidity.FieldLoop | TokenValidity.FileLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NODISPLAY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NODISPLAY_LENGTH", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NODRILL", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NODUPLICATES", TokenValidity.KeyLoop)
			expressions.Add("NOECHO", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOEDITFORMAT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOEXPLICIT_VALUE", TokenValidity.EnumMemberLoop)
			expressions.Add("NOFORMAT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOHELPID", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOHYPERLINK", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOINCREMENT", TokenValidity.KeySegmentLoop)
			expressions.Add("NOINFOLINE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOLANGUAGE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOLEAVE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOLONGDESC", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOMORE", TokenValidity.AnyLoop)
			expressions.Add("NONEGATIVE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOPAINTCHAR", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOPRECISION", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOPROMPT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NORANGE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NORECORDCOMPRESSION", TokenValidity.FileLoop)
			expressions.Add("NOREPORT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOSELECTIONS", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOSELWND", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOSTORED_GRFA", TokenValidity.FileLoop)
			expressions.Add("NOT_COUNTER_1", TokenValidity.Anywhere)
			expressions.Add("NOT_COUNTER_2", TokenValidity.Anywhere)
			expressions.Add("NOT_USERTOKEN_", TokenValidity.Anywhere)
			expressions.Add("NOTALPHA", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTARRAY", TokenValidity.FieldLoop)
			expressions.Add("NOTASCII", TokenValidity.FileLoop)
			expressions.Add("NOTBINARY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTBOOLEAN", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTBZERO", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTDATE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTDATEORTIME", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTDATETODAY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTDECIMAL", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTENUM", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTENUMERATED", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTIMEOUT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTINTEGER", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTISAM", TokenValidity.FileLoop)
			expressions.Add("NOTNUMERIC", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTOOLKIT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTOVERLAY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTPKSEGMENT", TokenValidity.FieldLoop)
			expressions.Add("NOTRADIOBUTTONS", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTRECORDTYPEFIXED", TokenValidity.FileLoop)
			expressions.Add("NOTRECORDTYPEMULTIPLE", TokenValidity.FileLoop)
			expressions.Add("NOTRECORDTYPEVARIABLE", TokenValidity.FileLoop)
			expressions.Add("NOTRELATIVE", TokenValidity.FileLoop)
			expressions.Add("NOTSTATICRFA", TokenValidity.FileLoop)
			expressions.Add("NOTSTRUCTFIELD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTTERABYTE", TokenValidity.FileLoop)
			expressions.Add("NOTTIME", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTUPPERCASE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTUSER", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOTUSERDEFINED", TokenValidity.FileLoop)
			expressions.Add("NOTUSERTIMESTAMP", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOUSERTEXT", TokenValidity.FieldLoop | TokenValidity.FileLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOVIEW_LENGTH", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NOWEB", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("NULLKEY", TokenValidity.KeyLoop)
			expressions.Add("NULLVALUE", TokenValidity.KeyLoop)
			expressions.Add("NUMERIC", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("OCNATIVE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("OCOBJECT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("OKBUTTON", TokenValidity.ButtonLoop)
			expressions.Add("OPTIONAL", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("OVERLAY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("PAGESIZE1024", TokenValidity.FileLoop)
			expressions.Add("PAGESIZE16384", TokenValidity.FileLoop)
			expressions.Add("PAGESIZE2048", TokenValidity.FileLoop)
			expressions.Add("PAGESIZE32768", TokenValidity.FileLoop)
			expressions.Add("PAGESIZE4096", TokenValidity.FileLoop)
			expressions.Add("PAGESIZE8192", TokenValidity.FileLoop)
			expressions.Add("PAGESIZE512", TokenValidity.FileLoop)
			expressions.Add("PAINTCHAR", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("PKSEGMENT", TokenValidity.FieldLoop)
			expressions.Add("PRECISION", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("PROMPT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("PROMPT_POSITION", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("QUICKSELECT", TokenValidity.ButtonLoop)
			expressions.Add("RADIOBUTTONS", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("RANGE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("READONLY", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("READWRITE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("RECORDCOMPRESSION", TokenValidity.FileLoop)
			expressions.Add("RECORDTYPEFIXED", TokenValidity.FileLoop)
			expressions.Add("RECORDTYPEMULTIPLE", TokenValidity.FileLoop)
			expressions.Add("RECORDTYPEVARIABLE", TokenValidity.FileLoop)
			expressions.Add("RELATIVE", TokenValidity.FileLoop)
			expressions.Add("REPORT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("REPORT_CENTER", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("REPORT_LEFT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("REPORT_RIGHT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("REQUIRED", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("REVERSE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_ALPHA", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_ASCENDING", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_AUTO_SEQUENCE", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_AUTO_TIMESTAMP", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_AUTO_TIMESTAMP_CREATED", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_AUTO_TIMESTAMP_UPDATED", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_DECIMAL", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_DESCENDING", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_NOCASE", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_SIGNED", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_TYPE_EXTERNAL", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_TYPE_FIELD", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_TYPE_LITERAL", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_TYPE_RECNUM", TokenValidity.KeySegmentLoop)
			expressions.Add("SEG_UNSIGNED", TokenValidity.KeySegmentLoop)
			expressions.Add("SELECTIONS", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("SELWND", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("SINGLE_SEGMENT", TokenValidity.KeyLoop)
			expressions.Add("SINGLE_TAG", TokenValidity.TagLoop)
			expressions.Add("STATICRFA", TokenValidity.FileLoop)
			expressions.Add("STORED_GRFA", TokenValidity.FileLoop)
			expressions.Add("STRUCTFIELD", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("STRUCTURE_FILES", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_HAS_UNIQUE_KEY", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_HAS_UNIQUE_PK", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_KEYS", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_LDESC", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_RELATIONS", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_TAGS", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_MULTIPLE_TAGS", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_SINGLE_TAG", TokenValidity.Anywhere)
			expressions.Add("STRUCTURE_UTEXT", TokenValidity.Anywhere)
			expressions.Add("TERABYTE", TokenValidity.FileLoop)
			expressions.Add("TEXTBOX", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("TIME", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("TIME_HHMM", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("TIME_HHMMSS", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("TIMENOW", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("TIMEOUT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("TOOLKIT", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("UNDERLINE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("UPPERCASE", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("USER", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("USERDEFINED", TokenValidity.FileLoop)
			expressions.Add("USERTEXT", TokenValidity.FieldLoop | TokenValidity.FileLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("USERTIMESTAMP", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("USERTOKEN_", TokenValidity.Anywhere)
			expressions.Add("VERBOSE_LOGGING", TokenValidity.Anywhere)
			expressions.Add("VIEW_LENGTH", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)
			expressions.Add("WEB", TokenValidity.FieldLoop | TokenValidity.KeySegmentLoop)

			if (context != ^null)
			begin
				data define, string
				foreach define in context.Taskset.Defines
					expressions.Add(define, TokenValidity.Anywhere)
			end
				
			expressionLookup = loadExpressionLookup(expressions)

			if (context != ^null)
			begin
				;; Add user defined tokens and custom extensions to the environment
				loadUserTokens()
				loadCustomExpanders()
				loadCustomEvaluators()
			end

		endmethod
		
		;;; <summary>
		;;; This method takes the declaration of an expansion token and registers the token into
		;;; the lookup tables that are used to process supported token variations and validate the
		;;; location of tokens.
		;;; </summary>
		;;; <param name="meta">Token metadata object</param>
		private method addLookupToken, void
			meta, @TokenMeta 
		proc
			if (meta.Modifiers.Count == 0) then
				modifierLookup.Add(meta.Name, TokenModifier.None)
			else
			begin
				data modifier, KeyValuePair<string, TokenModifier>
				foreach modifier in meta.Modifiers
				begin
					modifierLookup.Add(modifier.Key, modifier.Value)

					;; TODO: What is this doing? Ask Jeff why PascalCase needs special processing
					if (modifier.Value == TokenModifier.PascalCase)
					begin
						data upperName = modifier.Key.ToUpper()
						if (upperName != meta.Name)
						begin
							if (!typeLookup.ContainsKey(upperName))
								typeLookup.Add(upperName, meta.TypeOfToken)
							if (!canonicalNameLookup.ContainsKey(upperName))
								canonicalNameLookup.Add(upperName, meta.Name)
						end
					end
				end				
			end

			validityLookup.Add(meta.Name, meta.SeperatedValidity)
			typeLookup.Add(meta.Name, meta.TypeOfToken)
			requiresRps.Add(meta.Name, meta.RequiresRepository)
			requiresNamespace.Add(meta.Name, meta.RequiresNamespace)
			canonicalNameLookup.Add(meta.Name, meta.Name)

			;; If this is a paired token then add the closer to the closer lookup table
			if (meta.IsPaired)
				closerLookup.Add(meta.Name)

		endmethod
		
		private method metaUpper, string
			name, string 
		proc
			mreturn name.ToUpper()
		endmethod
		
		private method metaLower, string
			name, string 
		proc
			mreturn name
		endmethod
		
		private method metaMixed, string
			name, string 
		proc
			mreturn name.First().ToString().ToUpper() + String.Join<char>("", name.Skip(1))
		endmethod
		
		private method metaXf, string
			name, string 
			index, int 
		proc
			if (index == 0) then
				mreturn name.First().ToString().ToUpper() + String.Join<char>("", name.Skip(1))
			else
				mreturn name
		endmethod
		
		private method metaPascal, string
			name, string 
		proc
			mreturn name.First().ToString().ToUpper() + String.Join<char>("", name.Skip(1))
		endmethod
		
		private method metaCamel, string
			name, string 
			index, int 
		proc
			if (index > 0) then
				mreturn name.First().ToString().ToUpper() + String.Join<char>("", name.Skip(1))
			else
				mreturn name
		endmethod

		;;; <summary>
		;;; Creates a TokenMeta object for an expansion token that supports all case variation options.
		;;; </summary>
		;;; <param name="aName">Token name in upper case (e.g. "FIELD_NAME")</param>
		;;; <param name="aType">Token type</param>
		;;; <param name="aValidity">Token validity</param>
		;;; <param name="aRequiresRps">Requires repository information</param>
		;;; <returns>TokenMeta object</returns>
		private method makeTokenMeta_AllVariants, @TokenMeta
			aName, string
			aType, TokenType 
			aValidity, TokenValidity 
			aRequiresRps, boolean 
		proc
			data parts, [#]string
			.ifdef D_PORTABLE
			;TODO: Compiler bug workaround 11/30/2017
			data splitter, string, "_"
			parts = aName.Split(splitter.ToCharArray())
			.else
			parts = aName.Split("_")
			.endc

			data lowerCaseParts, @List<string>, parts.Select(lambda (str) {str.ToLower()}).ToList()
			data upperCaseParts, @List<string>, parts.Select(lambda (str) {str.ToUpper()}).ToList()

			data upperCase,  string, String.Join("_", lowerCaseParts.Select(metaUpper))
			data lowerCase,  string, String.Join("_", lowerCaseParts.Select(metaLower))
			data mixedCase,  string, String.Join("_", lowerCaseParts.Select(metaMixed))
			data xfCase,     string, String.Join("_", lowerCaseParts.Select(metaXf))
			data pascalCase, string, String.Join("",  lowerCaseParts.Select(metaPascal))
			data camelCase,  string, String.Join("",  lowerCaseParts.Select(metaCamel))

			data result = new TokenMeta()
			result.TypeOfToken = aType
			result.Name = string.Join("_", upperCaseParts)

			result.Modifiers = new Dictionary<string, TokenModifier>()
			result.Modifiers.Add(upperCase, TokenModifier.None)
			result.Modifiers.Add(lowerCase, TokenModifier.LowerCase)
			result.Modifiers.Add(pascalCase, TokenModifier.PascalCase)

			if (parts.Length > 1)
			begin
				result.Modifiers.Add(xfCase, TokenModifier.XfCase)
				result.Modifiers.Add(mixedCase, TokenModifier.MixedCase)
				result.Modifiers.Add(camelCase, TokenModifier.CamelCase)
			end

			result.Validity = aValidity
			result.RequiresRepository = aRequiresRps

			mreturn result

		endmethod

		;;; <summary>
		;;; Creates a TokenMeta object for an expansion token that supports only upper and lower case variations.
		;;; </summary>
		;;; <param name="aName">Token name in upper case (e.g. "FIELD_NAME")</param>
		;;; <param name="aType">Token type</param>
		;;; <param name="aValidity">Token validity</param>
		;;; <param name="aRequiresRps">Requires repository information</param>
		;;; <returns>TokenMeta object</returns>
		private method makeTokenMeta_UpperLower, @TokenMeta
			aName, string 
			aType, TokenType 
			aValidity, TokenValidity 
			aRequiresRps, boolean 
		proc
			data parts = aName.Split("_")

			data lowerCaseParts, @List<string>, parts.Select(lambda (str) {str.ToLower()}).ToList()
			data upperCaseParts, @List<string>, parts.Select(lambda (str) {str.ToUpper()}).ToList()

			data upperCase, string, string.Join("_", lowerCaseParts.Select(metaUpper))
			data lowerCase, string, string.Join("_", lowerCaseParts.Select(metaLower))

			data result = new TokenMeta()
			result.TypeOfToken = aType
			result.Name = string.Join("_", upperCaseParts)

			result.Modifiers = new Dictionary<string, TokenModifier>()
			result.Modifiers.Add(upperCase, TokenModifier.None)
			result.Modifiers.Add(lowerCase, TokenModifier.LowerCase)

			result.Validity = aValidity
			result.RequiresRepository = aRequiresRps

			mreturn result

		endmethod
		
		;;; <summary>
		;;; Expands Synergy logical names in a path specification.
		;;; </summary>
		;;; <param name="path">Path that may or may not contain Synergy logical name specifications.</param>
		;;; <returns>Path with logical name specifications expanded</returns>
		private method expandLogicals, string
			path, String 
		proc
			data newPath, string, path
			if (FileTools.ExpandLogicalName(newPath)) then
				mreturn newPath
			else
				throw new ApplicationException(String.Format("Failed to expand logical names in {0}", path))
		endmethod
		
		;;; <summary>
		;;; This method is used to process pre-processor tokens, the resulting value of which could contain
		;;; other tokens. First the "value" associated with the token is obtained (from a file or environment
		;;; variable) and then that value is tokenized. The resulting tokens become part of the overall
		;;; token stream for the template file.
		;;; </summary>
		;;; <param name="initialToken">Value of pre-processor token (e.g. FILE:name.ext)</param>
		;;; <returns>Collection of tokens</returns>
		private method tokenizePreProcessorToken, @List<Token>
			initialToken, string 
		proc
			;; initialToken will contain one of:
			;; 
			;;   ENV:envvar
			;;   ENVIFEXIST:data
			;;   FILE:filespec
			;;   FILEIFEXIST:filespec
			;; 
			;;   Or the name of an optional user token that has embedded tokens in its value

			data tokenName, string, initialToken.IndexOf(":") == -1 ? initialToken : initialToken.Substring(0, initialToken.IndexOf(":"))
			data tokenData, string, initialToken.Replace(tokenName + ":", "")
			data filespec, string, ""
			data tokens, @List<Token>, new List<Token>()
			
			using tokenName select
			("FILE"),
			begin
				try
				begin
					filespec = expandLogicals(tokenData)
					if (File.Exists(filespec)) then
						tokens = Tokenize(filespec)
					else
						throw new ApplicationException("")
				end
				catch (ex, @Exception)
				begin
					throw new ApplicationException(String.Format("Failed to read file {0} while processing token <{1}>", filespec, initialToken))
				end
				endtry
			end
			("FILEIFEXIST"),
			begin
				try
				begin
					filespec = expandLogicals(tokenData)
					if (File.Exists(filespec))
						tokens = Tokenize(filespec)
				end
				catch (ex, @Exception)
				begin
					;; That's OK, there was a problem expanding a logical, so we treat it as "file not found" for this token.
					nop
				end
				endtry
			end
			("ENV"),
			begin
				if (Environment.GetEnvironmentVariable(tokenData) == ^null)
					throw new ApplicationException(String.Format("Token <ENV:{0}> requires that environment variable {1} is defined!", tokenData, tokenData))
				tokens = Tokenize(Environment.GetEnvironmentVariable(tokenData))
			end
			("ENVIFEXIST"),
			begin
				if (!String.IsNullOrWhiteSpace(Environment.GetEnvironmentVariable(tokenData)))
					tokens = Tokenize(Environment.GetEnvironmentVariable(tokenData))
			end
			(),
			begin
				;; If we get here then we're dealing with an <OPTIONAL_USERTOKEN> that has
				;; embedded tokens in its value. We already parsed out the values earlier,
				;; so we just need to return them into the token stream.
				mreturn optionalUserTokens[tokenName]
			end
			endusing
			
			mreturn tokens

		endmethod
		
		;;; <summary>
		;;; This is the Tokenize method that is used by GodeGenerator
		;;; </summary>
		;;; <param name="tokens"></param>
		;;; <returns></returns>
		public method TokenizeCurrentTemplate, boolean
			out tokens, @List<Token> 
		proc
			tokens = Tokenize(context.CurrentTemplate)
			mreturn (!errorsReported)
		endmethod
		
		private method reportError, void
			message, string 
		proc
			if (context != ^null) then
				context.CurrentTask.ErrorLog(message)
			else
				throw new ApplicationException(message)
			errorsReported = true
		endmethod
		
		;;; <summary>
		;;; This is the main entry point to the functionality of this class. The method can
		;;; be called with a string that contains either a full file specification, or just
		;;; one or more tokens. If the passed value is found to be a file then the content
		;;; of the file is read and tokenized. If the passed value is not found to be a file
		;;; spec then the value is tokenized. 
		;;; </summary>
		;;; <param name="fileSpecOrTemplateCode">
		;;; Full path to a template file, or a string to be tokenized.
		;;; </param>
		;;; <returns>Collection of tokens</returns>
		public method Tokenize, @List<Token>
			fileSpecOrTemplateCode, string 
		proc
			data templateCode, string
			data fileName, string

			;; If we were passed a file spec then we'll try to read data from it.
			;; Otherwise we were just passed text that will be injected into the
			;; template code stream, e.g. from an <ENV:text> token.
			if (File.Exists(fileSpecOrTemplateCode)) then
			begin
				;; We have a file spec, read template code from the file
				try
				begin
					templateCode = File.ReadAllText(fileSpecOrTemplateCode)
					fileName = fileSpecOrTemplateCode
				end
				catch (ex, @Exception)
				begin
					reportError(String.Format("Failed to read file {0}. Error was {1}", fileSpecOrTemplateCode, ex.Message))
					mreturn ^null
				end
				endtry
			end
			else
			begin
				templateCode = fileSpecOrTemplateCode
				fileName = ""
			end

			data lineStarts = buildLineStarts(templateCode)
			data tokens = new List<Token>()
			data ix = 0

			while (ix < templateCode.Length) do
			begin
				data nextToken, @PossibleToken, nextPossibleToken(ix, templateCode)

				if (nextToken == ^null) then
				begin
					;; There was no next token, so add the remaining code as a final Text token
					tokens.Add(new Token(fileName, ix, templateCode.Length, false, templateCode.Substring(ix), TokenType.Text, TokenModifier.None, ^null, lineStarts, false, false))
					exitloop
				end
				else
				begin
					;; Remove the <> parts, and an uppercase copy without any leading /
					data nextTokenValue = templateCode.Substring(nextToken.StartsAtPosition + 1, (nextToken.EndsAtPosition - 1) - (nextToken.StartsAtPosition))
					data nextTokenValueUpper = nextTokenValue.ToUpper().TrimStart('/')

					;; Is the token a closer?
					data closer = nextTokenValue.StartsWith("/")

					;; The next token isn't here, so we have just text. Add a Text token.
					if (nextToken.StartsAtPosition != ix)
						tokens.Add(new Token(fileName, ix, nextToken.StartsAtPosition - 1, false, templateCode.Substring(ix, nextToken.StartsAtPosition - ix), TokenType.Text, TokenModifier.None, ^null, lineStarts, false, false))
					
					if (nextToken.IsComment) then
					begin
						;; It's a template file comment. Ignore it!
						nop
					end
					else if (nextToken.IsPreProcessor) then
					begin
						;; It's a pre-processor token. Tokenize it's "content".
						try
						begin
							tokens.AddRange(tokenizePreProcessorToken(nextTokenValue))
						end
						catch (ex, @ApplicationException)
						begin
							reportError(ex.Message)
							mreturn ^null
						end
						endtry
					end
					else
					begin
						;; It's just a token (it's already been validated by nextPossibleToken)
						data cannonicalExpressionValue, string, canonicalNameLookup[nextTokenValueUpper]
						data newToken, @Token, new Token(fileName, nextToken.StartsAtPosition, nextToken.EndsAtPosition, closer, cannonicalExpressionValue, typeLookup[nextTokenValueUpper], modifierLookup[nextTokenValue.TrimStart('/')], validityLookup[cannonicalExpressionValue], lineStarts, requiresRps[cannonicalExpressionValue], requiresNamespace[cannonicalExpressionValue])

						;; Are we adding an </OPTIONAL_USERTOKEN>?
						if (((newToken.TypeOfToken == TokenType.FileHeader) && (newToken.Value == "OPTIONAL_USERTOKEN")) && newToken.Closer)
						begin
							;; In most cases the previous token should be a text token, and the
							;; one before that should be the matching <OPTIONAL_USERTOKEN>.
							;; If this is not true then there are probably other tokens in the usertoken value!
							if (((tokens[tokens.Count - 2].TypeOfToken == TokenType.FileHeader) && (tokens[tokens.Count - 2].Value == "OPTIONAL_USERTOKEN")) && (tokens[tokens.Count - 1].TypeOfToken == TokenType.Text)) then
							begin
								;; There is only a single text token between the <OPTIONAL_USERTOKEN> tags.
								;; It should be a NAME=VALUE expression.
								;; Make sure the format looks OK
								data userTokenExpression = tokens[tokens.Count - 1].Value

								if (!userTokenExpression.Contains("=") || userTokenExpression.Trim().StartsWith("="))
								begin
									reportError("Token <OPTIONAL_USERTOKEN> contains an incorrectly formatted value!")
									mreturn ^null
								end

								;; Split the expression into its name and value parts
								data parts = userTokenExpression.Split('=')
								parts[0] = parts[0].ToUpper()

								;; Do we already have a user token with this name?
								if (context.UserTokens.FirstOrDefault(lambda (token) {token.Name == parts[0]}) == ^null)
								begin
									;; No, so we'll add it using the default value provided
									context.UserTokens.Add(new UserToken(parts[0], parts[1]))

									;; And register it with Tokenizer
									addLookupToken(new TokenMeta() { Name = parts[0], TypeOfToken = TokenType.User, Validity = TokenValidity.Anywhere })
								end
							end
							else
							begin
								;;It looks like there may be additional tokens within the value of the optional usertokens default value.

								;; Find the index of the opening <OPTIONAL_USERTOKEN> token
								data index, int, (tokens.IndexOf(tokens.Last(lambda (token) {(token.TypeOfToken == TokenType.FileHeader) && (token.Value == "OPTIONAL_USERTOKEN")})))

								;; Extract the subsequent tokens that represent the value for this token
								data valueTokens, @List<Token>, tokens.Skip(index + 1).ToList()

								;; Extract the user token name from the first node
								data tokenName, string, valueTokens[0].Value.Substring(0, valueTokens[0].Value.IndexOf("="))

								;; Do we already have a user defined token with this name?
								if (context.UserTokens.FirstOrDefault(lambda (token) {token.Name == tokenName}) == ^null)
								begin
									;; No we don't. Remove the name and = from the first node
									valueTokens[0].Value = valueTokens[0].Value.Remove(0, valueTokens[0].Value.IndexOf("=") + 1)

									;; If there is nothing left in the first text token then remove it
									if (valueTokens[0].Value == String.Empty)
										valueTokens.RemoveAt(0)

									;; Add the collection of tokens to the new dictionary
									optionalUserTokens.Add(tokenName, valueTokens)

									;; And register it with Tokenizer as a pre-processor type
									addLookupToken(new TokenMeta() { Name = tokenName, TypeOfToken = TokenType.PreProcessor, Validity = TokenValidity.Anywhere })

								end
							end
						end

						;;Do we have a user-defined token and are we pre-processing them?
						if (newToken.TypeOfToken == TokenType.User && context.CurrentTask.PreProcessUserTokens) then
						begin	
							;;Pre-processing user defined tokens means that instead of adding the user-defined
							;;token to the token stream, we will tokenize the value of the user-defined token
							;;here and now.
							;;
							;;In most cases this will result in a single text token being added to the token
							;;stream. But if the value of the user-defined token happens to include other
							;;tokens then the value will be expanded out to multiple tokens here.

							;;Get the value of the user-defined token
							lambda findUserToken(tkn) tkn.Name == newToken.Value
							data userTokenValue = Context.UserTokens.First(findUserToken).Value

							;;Tokenize the value
							data userTokenTokens = Tokenize(userTokenValue)

							;;Add the resulting tokens to the token stream
							tokens.AddRange(userTokenTokens)
						end
						else
						begin
							;;Add the token to the token stream
							tokens.Add(newToken)
						end
					end

					ix = nextToken.EndsAtPosition + 1

					if (nextToken.IsExpression)
					begin
						data nextExpression, @Tuple<int, int, List<TokenValidity>>, nextExpressionToken(ix, templateCode)
						if (nextExpression != ^null)
						begin
							data expressionValue, string, templateCode.Substring(nextExpression.Item1, nextExpression.Item2 - nextExpression.Item1)
							;; TODO: Does this expression require repository structure processing?
							data requiresRps, boolean, false
							tokens.Add(new Token(fileName, nextExpression.Item1, nextExpression.Item2, false, expressionValue, TokenType.Expression, TokenModifier.None, nextExpression.Item3, lineStarts, requiresRps, false))
							ix = nextExpression.Item2 + 1
						end
					end

				end
			end

			mreturn tokens

		endmethod
		
		;;; <summary>
		;;; Returns an array of the offsets in the template file where new lines start.
		;;; </summary>
		;;; <param name="templateCode"></param>
		;;; <returns></returns>
		private static method buildLineStarts, [#]int
			templateCode, string 
		proc
			data lineStarts = new List<int>()
			lineStarts.Add(0)
			
			data ix, int
			for ix from 0 thru templateCode.Length - 1
			begin
				if ((templateCode[ix] == %char(13) && templateCode.Length > ix + 1 && templateCode[ix + 1] == %char(10)) || templateCode[ix] == %char(10))
				begin
					if (templateCode[ix] == %char(10)) then
						lineStarts.Add(ix + 1)
					else
					begin
						lineStarts.Add(ix + 2)
						^incr(ix, true)
					end
				end
			end
			
			mreturn lineStarts.ToArray()

		endmethod
		
		;;; <summary>
		;;; Represents a possible token in the template text.
		;;; </summary>
		private class PossibleToken
			
			public StartsAtPosition, int
			public EndsAtPosition, int
			public IsCloser, boolean
			public IsExpression, boolean
			public IsComment, boolean
			public IsPreProcessor, boolean
			
			public method PossibleToken
				startIndex, int 
				endIndex, int 
				closer, boolean 
				expression, boolean 
				comment, boolean 
				preProcessor, boolean 
			proc
				StartsAtPosition = startIndex
				EndsAtPosition = endIndex
				IsCloser = closer
				IsExpression = expression
				IsComment = comment
				IsPreProcessor = preProcessor
			endmethod

		endclass
		
		;;; <summary>
		;;; Returns the next possible token in the template text.
		;;; </summary>
		;;; <param name="searchFrom">Position where to start looking for a possible token.</param>
		;;; <param name="templateCode">Template text to search.</param>
		;;; <returns>PossibleToken instance, or null if no possible tokens found.</returns>
		private method nextPossibleToken, @PossibleToken
			searchFrom, int 
			templateCode, string 
		proc
			data foundPossibleToken = false
			data isCloser = false
			data isComment = false
			data isExpression = false
			data possibleTokenStartsAt, int, -1

			;; Character by character looking for a token
			data ix, int
			for ix from searchFrom thru templateCode.Length - 1
			begin
				;; Did we find a newline?
				data foundNewLine, boolean, (((templateCode[ix] == %char(13)) && (templateCode.Length > ix + 1) && (templateCode[ix + 1] == %char(10))) || (templateCode[ix] == %char(10)))

				;; Did we find the start of a template file comment (;//)?
				if (templateCode.Length > ix + 2 && templateCode[ix] == ';' && templateCode[ix + 1] == '/' && templateCode[ix + 2] == '/') then
				begin
					possibleTokenStartsAt = ix
					isComment = true
				end
				else if (isComment && foundNewLine) then
				begin
					;; We found the END of a template file comment
					if ((templateCode[ix] == %char(13)) && (templateCode.Length > ix + 1) && (templateCode[ix + 1] == %char(10)))
						^incr(ix, true)
					mreturn new PossibleToken(possibleTokenStartsAt, ix, false, false, true, false)
				end
				else if (isComment) then
				begin
					;; We're looking for the newline at the end of a comment and didn't find it.
					;; Move on to the next character.
					nextloop
				end
				else if (foundPossibleToken && (templateCode[ix] == '<')) then
				begin
					;; Looks like the previous < we found wasn't the start of a token after all!
					;; Start over with the < that we just found
					possibleTokenStartsAt = ix
					isCloser = false
				end
				else if (!foundPossibleToken) then
				begin
					;; Still looking for the start of a possible token. Do we have one now?
					if (templateCode[ix] == '<')
					begin
						;; Yes, this could be the start of a token!
						isCloser = false
						foundPossibleToken = true
						possibleTokenStartsAt = ix
					end
				end
				else
				begin
					;; We previously found < and we're winding forward to figure out what it is
					;; Did we find the end of a possible token?
					;; Or a space MIGHT indicate an expression
					if ((templateCode[ix] == '/') && ((ix - possibleTokenStartsAt) == 1)) then
					begin
						;; It's a / and it's next to the <. so it's a possible closer token
						isCloser = true
					end
					else if (char.IsControl(templateCode[ix])) then
					begin
						;; It's a control character, so the token we were looking at can't be a token
						foundPossibleToken = false
						possibleTokenStartsAt = -1
						isExpression = false
					end
					else if ((templateCode[ix] == '>') || (templateCode[ix] == ' '))
					begin
						;; So we found a > or a space after an <

						;; For it to be a POSSIBLE expression the previous two characters need to be IF
						if ((templateCode[ix] == ' ') && (ix >= 2) && (templateCode[ix - 2] == 'I') && (templateCode[ix - 1] == 'F'))
							isExpression = true

						;; Get the start and end indexes of the VALUE of the possible token (withoit the < > or " ")
						data realStartIndex, int, (possibleTokenStartsAt + 1)
						data realEndIndex, int, ix - 1
						if (isCloser)
							realStartIndex += 1

						;; Make sure we aren't looking at a > or " " immediately after the <
						if ((realEndIndex - realStartIndex + 1) > 0) then
						begin
							data nextToken, string, templateCode.Substring(realStartIndex, realEndIndex - realStartIndex + 1)
							if (nextToken.Contains(':') && (nextToken != ":")) then
							begin
								nextToken = nextToken.Split(':')[0]
								if (isPreProcessorToken(nextToken)) then
									mreturn new PossibleToken(possibleTokenStartsAt, ix, isCloser, isExpression, false, true)
								else
								begin
									;; So we thought we had a token, but it turns out we don't!
									foundPossibleToken = false
									possibleTokenStartsAt = -1
								end
							end
							else
							begin
								if (isValidToken(nextToken)) then
									mreturn new PossibleToken(possibleTokenStartsAt, ix, isCloser, isExpression, false, optionalUserTokens.ContainsKey(nextToken))
								else
								begin
									;; So we thought we had a token, but it turns out we don't!
									foundPossibleToken = false
									possibleTokenStartsAt = -1
								end
							end
						end
						else
						begin
							;; The > or " " was right after the <
							;; Ignore the < and move on
							possibleTokenStartsAt = -1
							isCloser = false
							isExpression = false
							foundPossibleToken = false
						end
					end
				end
			end
			
			;; TODO: I think the intention was never to get here, but sometimes we do!
			mreturn ^null

		endmethod
		
		;;; <summary>
		;;; Does a string represent the name of a known token?
		;;; </summary>
		;;; <param name="tokenValue">Value to test</param>
		;;; <returns>true if the value is the name of a token, otherwise false</returns>
		private method isValidToken, boolean
			tokenValue, string 
		proc
			if (tokenValue.StartsWith("/")) then
				mreturn closerLookup.Contains(tokenValue.ToUpper())
			else
			begin
				;;Main token lookup - this will validate most tokens
				if (modifierLookup.ContainsKey(tokenValue))
					mreturn true
				
				;;And now the exceptions!
				if ( tokenValue.StartsWith("REMAINING_EXCLUSIVE_MAX_")
				&	|| tokenValue.StartsWith("REMAINING_INCLUSIVE_MAX_"))
				begin
					;;Declare the token as valid so that tokenization works.
					;;Further validation will take place later during expansion.
					if (!canonicalNameLookup.ContainsKey(tokenValue))
					begin
						addLookupToken( new TokenMeta() {Name = tokenValue, TypeOfToken = TokenType.LoopUtility, IsPaired = false, Validity = TokenValidity.AnyLoop})
						mreturn true
					end
				end

				;;Whatever you found, it's not a CodeGen token!
				mreturn false

			end
		endmethod
		
		;;; <summary>
		;;; Does a string represent the name of a known pre-processor token?
		;;; </summary>
		;;; <param name="tokenValue">Value to test</param>
		;;; <returns>true if the value is the name of a pre-processor token, otherwise false</returns>
		private method isPreProcessorToken, boolean
			tokenValue, string 
		proc
			if (typeLookup.ContainsKey(tokenValue.ToUpper())) then
				mreturn (typeLookup[tokenValue.ToUpper()] == TokenType.PreProcessor)
			else
				mreturn false
		endmethod
		
		;;; <summary>
		;;; 
		;;; </summary>
		;;; <param name="startIndex"></param>
		;;; <param name="templateCode"></param>
		;;; <returns></returns>
		private method nextExpressionToken, @Tuple<int, int, List<TokenValidity>>
			startIndex, int 
			templateCode, string 
		proc
			data startedToken, boolean, false
			data startedTokenIndex, int, -1
			data ix, int

			for ix from startIndex thru templateCode.Length - 1
			begin
				if (!startedToken) then
				begin
					if (char.IsLetter(templateCode[ix]))
					begin
						startedToken = true
						startedTokenIndex = ix
					end
				end
				else
				begin
					if (char.IsLetterOrDigit(templateCode[ix]) || (templateCode[ix] == '_')) then
					begin
						nextloop
					end
					else if ((templateCode[ix] == ' ') || (templateCode[ix] == '>')) then
					begin
						data expressionType, @List<TokenValidity>
						data expstring, string, templateCode.Substring(startedTokenIndex, ix - startedTokenIndex)

						if (expressionLookup.TryGetValue(expstring, expressionType)) then
						begin
							mreturn Tuple.Create(startedTokenIndex, ix, expressionType)
						end
						else if (expstring.ToUpper().StartsWith("CUSTOM_")) then
						begin
							mreturn Tuple.Create(startedTokenIndex, ix, customValidity)
						end
						else if ((expstring.ToUpper().StartsWith("USERTOKEN_"))
						&	||   (expstring.ToUpper().StartsWith("NOT_USERTOKEN_"))) then
						begin
							mreturn Tuple.Create(startedTokenIndex, ix, userTokenValidity)
						end
						else if (expstring.StartsWith("DEFINED_") || expstring.StartsWith("NOT_DEFINED_")) then
						begin
							mreturn Tuple.Create(startedTokenIndex, ix, userTokenValidity)
						end
						else if (expstring.StartsWith("COUNTER_1_") || expstring.StartsWith("COUNTER_2_")) then
						begin
							mreturn Tuple.Create(startedTokenIndex, ix, userTokenValidity)
						end
						else if (expstring.StartsWith("PROCESSED_EXCLUSIVE_") 
						&	||   expstring.StartsWith("PROCESSED_INCLUSIVE_")
						&	||   expstring.StartsWith("REMAINING_EXCLUSIVE_") 
						&	||   expstring.StartsWith("REMAINING_INCLUSIVE_")
						&	||   expstring.StartsWith("TOTAL_ITEMS_")) then
						begin
							mreturn Tuple.Create(startedTokenIndex, ix, loopUtilityTokenValidity)
						end
						else
						begin
							;; Invalid expression
							reportError(String.Format("Invalid expression <IF {0}> at offset {1}!", expstring, startedTokenIndex - 4, ""))
							exitloop
						end
					end
					else if (char.IsControl(templateCode[ix])) then
						exitloop
					else
					begin
						startedToken = false
						startedTokenIndex = -1
					end
				end
			end
			
			mreturn ^null

		endmethod
		
		;;; <summary>
		;;; Writes the current collection of tokens to a file for debugging purposes.
		;;; </summary>
		;;; <param name="tokens">Collection of tokens.</param>
		;;; <param name="fileSpec">File to write tokens to.</param>
		;;; <returns>Returns true if the file was successfully created</returns>
		public static method WriteTokensToFile, boolean
			tokens, @List<Token> 
			fileSpec, string 
		proc
			try
			begin
				disposable data file, @StreamWriter, File.CreateText(fileSpec)
				data tkn, @Token
				foreach tkn in tokens
					file.WriteLine(tkn.ToString())
				file.Close()
				mreturn true
			end
			catch (ex, @Exception)
			begin
				mreturn false
			end
			endtry
		endmethod
		
		private method loadUserTokens, void
		proc
			;; Plug in any user-defined tokens
			if ((context.UserTokens != ^null) && (context.UserTokens.Count > 0))
			begin
				data ut, @UserToken
				foreach ut in context.UserTokens
				begin
					data newMeta, @TokenMeta, new TokenMeta()
					newMeta.Name = ut.Name
					newMeta.TypeOfToken = TokenType.User
					newMeta.Validity = TokenValidity.Anywhere
					addLookupToken(newMeta)
				end
			end
		endmethod
		
		private method loadCustomExpanders, void
		proc
			;; Plug in any custom token expanders
			if ((context.CustomTokenExpanders != ^null) && (context.CustomTokenExpanders.Count > 0))
			begin
				data customexpander, @Tuple<String, String, TokenValidity, TokenCaseMode, Func<Token, FileNode, IEnumerable<LoopNode>, String>>

				foreach customexpander in context.CustomTokenExpanders
				begin
					using (customexpander.Item3) select

					(TokenValidity.Anywhere),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.Generic, TokenValidity.Anywhere, false))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.Generic, TokenValidity.Anywhere, false))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.Generic, Validity = TokenValidity.Anywhere, RequiresRepository = false})
						endusing
					end

					(TokenValidity.NotInLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							nop
						(TokenCaseMode.UppercaseAndLowerCase),
							nop
						(TokenCaseMode.UppercaseOnly),
							nop
						endusing
					end

					(TokenValidity.AnyLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.LoopUtility, TokenValidity.AnyLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.LoopUtility, TokenValidity.AnyLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.LoopUtility, Validity = TokenValidity.AnyLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.FieldLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.FieldLoop, TokenValidity.FieldLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.FieldLoop, TokenValidity.FieldLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.FieldLoop, Validity = TokenValidity.FieldLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.FieldSelectionLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.FieldSelectionLoop, TokenValidity.FieldSelectionLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.FieldSelectionLoop, TokenValidity.FieldSelectionLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.FieldSelectionLoop, Validity = TokenValidity.FieldSelectionLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.KeyLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.KeyLoop, TokenValidity.KeyLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.KeyLoop, TokenValidity.KeyLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.KeyLoop, Validity = TokenValidity.KeyLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.KeySegmentLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.KeySegmentLoop, TokenValidity.KeySegmentLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.KeySegmentLoop, TokenValidity.KeySegmentLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.KeySegmentLoop, Validity = TokenValidity.KeySegmentLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.EnumLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.EnumLoop, TokenValidity.EnumLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.EnumLoop, TokenValidity.EnumLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.EnumLoop, Validity = TokenValidity.EnumLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.EnumMemberLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.EnumMemberLoop, TokenValidity.EnumMemberLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.EnumMemberLoop, TokenValidity.EnumMemberLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.EnumMemberLoop, Validity = TokenValidity.EnumMemberLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.RelationLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.RelationLoop, TokenValidity.RelationLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.RelationLoop, TokenValidity.RelationLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.RelationLoop, Validity = TokenValidity.RelationLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.TagLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.TagLoop, TokenValidity.TagLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.TagLoop, TokenValidity.TagLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.TagLoop, Validity = TokenValidity.TagLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.StructureLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.StructureLoop, TokenValidity.StructureLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.StructureLoop, TokenValidity.StructureLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.StructureLoop, Validity = TokenValidity.StructureLoop, RequiresRepository = true})
						endusing
					end

					(TokenValidity.ButtonLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.ButtonLoop, TokenValidity.ButtonLoop, false))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.ButtonLoop, TokenValidity.ButtonLoop, false))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.ButtonLoop, Validity = TokenValidity.ButtonLoop, RequiresRepository = false})
						endusing
					end

					(TokenValidity.FileLoop),
					begin
						using (customexpander.Item4) select
						(TokenCaseMode.AllCasingOptions),
							addLookupToken(makeTokenMeta_AllVariants(customexpander.Item1, TokenType.FileLoop, TokenValidity.FileLoop, true))
						(TokenCaseMode.UppercaseAndLowerCase),
							addLookupToken(makeTokenMeta_UpperLower(customexpander.Item1, TokenType.FileLoop, TokenValidity.FileLoop, true))
						(TokenCaseMode.UppercaseOnly),
							addLookupToken(new TokenMeta() {Name = customexpander.Item1, TypeOfToken = TokenType.FileLoop, Validity = TokenValidity.FileLoop, RequiresRepository = true})
						endusing
					end

					endusing

				end
			end

		endmethod
		
		private method loadCustomEvaluators, void
		proc
			;; Plug in custom expression evaluators
			if ((context.CustomExpressionEvaluators != ^null) && (context.CustomExpressionEvaluators.Count > 0))
			begin
				data extension, @Tuple<string, string, TokenValidity, Func<Token, FileNode, IEnumerable<LoopNode>, boolean>>
				
				foreach extension in context.CustomExpressionEvaluators
				begin
					data expressionTypes, @List<TokenValidity>, new List<TokenValidity>()
					data enumValue, Enum
				
					foreach enumValue in Enum.GetValues(extension.Item3.GetType())
						if (extension.Item3.HasFlag(enumValue))
							expressionTypes.Add((TokenValidity)enumValue)
					
					expressionLookup.Add(extension.Item1, expressionTypes)
				end
				
			end
		endmethod

	endclass

endnamespace

